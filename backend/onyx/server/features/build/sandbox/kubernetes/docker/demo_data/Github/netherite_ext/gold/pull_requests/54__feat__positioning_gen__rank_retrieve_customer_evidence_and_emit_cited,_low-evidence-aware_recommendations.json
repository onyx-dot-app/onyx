{
  "id": "https://github.com/onyx-dot-app/onyx#54",
  "semantic_identifier": "54: feat: Positioning gen: rank/retrieve customer evidence and emit cited, low-evidence-aware recommendations",
  "title": null,
  "source": "github",
  "doc_updated_at": "2025-05-13",
  "metadata": {
    "object_type": "PullRequest",
    "id": "54",
    "merged": "True",
    "state": "closed",
    "user": {
      "login": "michael_anderson",
      "name": "michael_anderson",
      "email": "michael_anderson@netherite-extraction.onyx.app"
    },
    "assignees": [
      {
        "login": "kevin_sullivan",
        "name": "kevin_sullivan",
        "email": "kevin_sullivan@netherite-extraction.onyx.app"
      }
    ],
    "repo": "netherite-ext/gold",
    "num_commits": "3",
    "num_files_changed": "72",
    "labels": [],
    "created_at": "2025-05-13",
    "updated_at": "2025-05-13",
    "closed_at": "2025-05-27"
  },
  "doc_metadata": {
    "repo": "netherite-ext/gold",
    "hierarchy": {
      "source_path": [
        "netherite-ext",
        "gold",
        "pull_requests"
      ],
      "owner": "netherite-ext",
      "repo": "gold",
      "object_type": "pull_request"
    }
  },
  "sections": [
    {
      "text": "## Description\r\n\r\n## Summary\nUpdates the positioning recommendation generator to explicitly prioritize captured customer language/evidence for the requested target segment and to include lightweight citations in all generated value props, differentiators, and objection handling.\n\n## What changed\n- Added an evidence retrieval + ranking step ahead of generation that:\n  - Filters evidence by target segment (and related tags/metadata when present).\n  - Ranks records by relevance to the user prompt/output section using a hybrid scorer (keyword overlap + embedding similarity) with recency/quality tie-breakers.\n  - Returns a bounded, deduped top-K evidence set per section (value props / differentiators / objections).\n- Introduced a structured \u201cevidence context\u201d passed into the LLM prompt, preserving:\n  - Original customer phrasing (quotes/snippets).\n  - Artifact metadata needed for citations.\n- Implemented lightweight citations in outputs:\n  - Each claim is associated with one or more citations formatted as `{source_type}:{artifact_ref}` (e.g., `call_transcript:call_123`, `interview_note:note_45`, `survey_response:survey_9#q3`).\n  - Generator emits citations inline or in a \u201cSources\u201d list per section (configurable).\n- Added guardrails to reduce uncited assertions:\n  - When evidence exists for a section, the model is instructed and post-validated to avoid uncited claims.\n  - If a sentence/claim lacks citations while evidence was available, the system either (a) regenerates with stricter instructions or (b) flags it as unsupported depending on configuration.\n- Added graceful degradation for sparse evidence:\n  - If retrieved evidence is below a minimum threshold, the generator clearly labels recommendations as **low evidence** and avoids confident, generic claims.\n  - Output includes a short \u201cEvidence gaps\u201d note describing what\u2019s missing (e.g., no objections captured for this segment).\n\n## Implementation notes\n- New evidence retrieval module integrated into the positioning pipeline (called once per request; section-level retrieval uses the same candidate pool with section-specific ranking).\n- Prompt schema extended to include `evidence_items[]` with `text`, `segment`, `source_type`, `artifact_ref`, and optional `timestamp`.\n- Added post-processing validation to:\n  - Ensure required citation fields are present.\n  - Detect sections with evidence available but missing citations.\n  - Apply low-evidence labeling rules when retrieval confidence/coverage is low.\n\n## User-visible behavior\n- Recommendations now include customer-language snippets and citations.\n- When evidence is thin, the generator explicitly indicates low-confidence/low-evidence outputs instead of filling with generic positioning.\n\n## Testing\n- Added unit tests for evidence ranking/filtering and citation formatting.\n- Added integration tests verifying:\n  - Citations appear when evidence exists.\n  - Low-evidence labeling triggers when retrieval returns insufficient items.\n  - Guardrail behavior prevents uncited claims when evidence is available.\n\r\n\r\n## How Has This Been Tested?\r\n\r\nstaging\r\n",
      "link": "https://github.com/onyx-dot-app/onyx#54"
    }
  ],
  "primary_owners": [],
  "secondary_owners": []
}