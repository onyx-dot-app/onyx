{
  "id": "c645511058cd4db39a0e0084e6bdb638",
  "semantic_identifier": "Impact--Backfill messaging experiment outcome metrics using canonical stage mapping.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-11-06",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Impact--Backfill messaging experiment outcome metrics using canonical stage mapping.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "This feature will restore trust and comparability in messaging experiment reporting by recomputing historical outcome metrics (win rate, pipeline velocity, and conversion) using the new canonical stage/event normalization. Today, older experiments reflect legacy stage mappings, which can make results appear to \u201cchange\u201d relative to newer experiments or to pipeline reality. Backfilling aligns all experiments to the same funnel definitions, enabling apples-to-apples analysis across time.\n\nWe will implement an idempotent backfill job that re-aggregates outcomes from normalized funnel stages and either overwrites or versions the stored experiment outcome snapshots. The idempotency requirement ensures the job can be safely rerun (e.g., after schema tweaks, partial failures, or incremental rollouts) without duplicating or corrupting results. Versioning/overwrite behavior will be chosen to balance auditability (ability to trace what changed) with simplicity in downstream consumers.\n\nThe primary product impact is improved metric accuracy and reduced confusion for users reviewing historical experiments, particularly in dashboards, experiment detail pages, and any exports or APIs that surface these snapshots. Secondary impacts include more reliable trend analysis, better decision-making on messaging performance, and reduced support burden from discrepancies between \u201cold\u201d and \u201cnew\u201d experiment metrics. Internally, this also de-risks future funnel changes by establishing a repeatable backfill mechanism.\n\nWe\u2019ll validate by selecting a small set of known experiments with expected outcomes, confirming recalculated metrics are consistent with pre-normalization intent, and ensuring newly created experiments remain stable (no regressions) post-normalization. We should anticipate some metric deltas where legacy mappings were incorrect; those changes are desired but should be communicated and, if possible, visible via snapshot version metadata. Success is defined by consistent metrics across historical and new experiments under the canonical mapping, with monitoring for unexpected large shifts and job-level correctness (completeness, rerun safety, and performance).",
      "link": "https://www.onyx.app/73361"
    }
  ],
  "primary_owners": [
    "kenji_watanabe@netherite-extraction.onyx.app"
  ],
  "secondary_owners": []
}