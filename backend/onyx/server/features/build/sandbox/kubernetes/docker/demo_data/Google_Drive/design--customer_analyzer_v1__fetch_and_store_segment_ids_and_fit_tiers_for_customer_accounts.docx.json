{
  "id": "c0e5612560cf421ea793d8a718ff9476",
  "semantic_identifier": "Design--Customer_Analyzer v1: Fetch and store segment IDs + fit tiers for customer accounts.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-08-27",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Customer_Analyzer v1: Fetch and store segment IDs + fit tiers for customer accounts.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "This feature adds the initial integration layer between Issue_Tracker and Customer_Analyzer to enrich customer/account records associated with ingested support conversations. When a conversation is processed and references one or more customer accounts, we will call Customer_Analyzer to fetch (a) the set of segment IDs and (b) the fit tier for each account. The goal is to make these attributes available as durable, queryable fields on the Issue_Tracker customer/account model without introducing any downstream logic (e.g., prioritization, UI, or analytics slicing) in this version.\n\nOn ingestion (or shortly after via an async job), the system will batch requests to Customer_Analyzer for all distinct account identifiers observed in the conversation payload. The integration should be resilient: timeouts/retries with backoff, per-account partial success handling, and safe fallbacks when Customer_Analyzer returns empty results. Responses will be normalized into canonical internal representations (e.g., `segment_ids: string[]`, `fit_tier: enum | string`) and stored alongside minimal freshness metadata.\n\nWe will extend the Issue_Tracker account model with `segment_ids`, `fit_tier`, and `last_fetched_at` (and optionally a lightweight `fetch_status` / `fetch_error_code` for observability). Updates are idempotent: writing the same values should be a no-op aside from freshness updates if desired, and concurrent fetches should not corrupt state. Missing/unknown values are handled gracefully by storing `NULL`/empty arrays and setting `last_fetched_at` only when a successful fetch completes; failures should not erase previously known values unless explicitly instructed by the response contract.\n\nOperationally, we\u2019ll include basic instrumentation (request counts, latency, error rates, and per-provider failure reasons) and a configurable staleness threshold to avoid refetching too frequently (e.g., skip fetch if `last_fetched_at` is within N hours). This ticket explicitly stops at retrieval + persistence; any priority weighting, routing logic, UI exposure, or reporting built on these fields will be handled in follow-up work once the data pipeline is stable and validated.",
      "link": "https://www.onyx.app/52713"
    }
  ],
  "primary_owners": [
    "kevin_sullivan"
  ],
  "secondary_owners": []
}