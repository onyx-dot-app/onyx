{
  "id": "3342b3d469174342945212c3e3c76431",
  "semantic_identifier": "Design--Update positioning generation to prioritize and cite captured customer language/evidence.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-04-22",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Update positioning generation to prioritize and cite captured customer language/evidence.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "### Overview\nWe will update the positioning recommendation generator so that it preferentially grounds value propositions, differentiators, and objection handling in captured customer language/evidence for the selected target segment. The generator will explicitly retrieve the most relevant evidence artifacts (e.g., call notes, interview transcripts, survey responses, sales notes) and weave verbatim or closely paraphrased language into the output. Each generated claim will carry a lightweight citation to the underlying source to improve trust and enable quick review.\n\n### Evidence retrieval + ranking\nIntroduce an \u201cevidence retrieval\u201d step ahead of generation: given `{segment, product/context, JTBD/initiative (optional)}`, query the evidence store and rank results by segment match, semantic similarity to the requested positioning topic, recency, and artifact quality signals (e.g., tagged as \u201cvalidated,\u201d presence of direct quotes). Return a compact evidence bundle containing top-N snippets with metadata `{source_type, artifact_id/url, timestamp, segment tags, snippet_text}`. If no high-confidence matches exist, return an empty/low-confidence bundle with a reason code (e.g., \u201cno segment-tagged artifacts,\u201d \u201conly stale artifacts\u201d).\n\n### Grounded generation + citations\nUpdate prompt/templating so the model must generate positioning elements from the retrieved evidence bundle: (1) value props must reference at least one snippet, (2) differentiators must cite evidence and specify \u201cwhy it matters\u201d in customer terms, and (3) objections must include an evidence-backed response and, when present, a cited example of the objection wording. Output format will include inline citations per bullet (e.g., `[Interview \u2022 INT-1432]`, `[Call \u2022 GONG-8821]`) and an \u201cEvidence summary\u201d section listing all sources used. Add a guardrail pass that checks for uncited assertions when evidence exists for that topic; if a claim lacks citation while relevant evidence is available, either attach an appropriate citation or mark the claim as \u201cneeds evidence\u201d and exclude it from the primary recommendations.\n\n### Graceful degradation and UX signaling\nWhen evidence is sparse or low-confidence, the system will avoid generic, authoritative claims and instead produce \u201chypothesis\u201d recommendations explicitly labeled as low-evidence (e.g., \u201cLow evidence: 1 artifact, 90+ days old\u201d) along with suggested next evidence to collect (e.g., \u201ccapture 3 segment interviews focused on onboarding friction\u201d). The UI/API response will include an `evidence_score` (0\u20131), counts by source type, and per-claim `citation_count` and `confidence` so downstream consumers can filter or highlight low-evidence outputs. Success criteria: higher citation coverage (target >90% of claims cited when evidence exists), reduced generic wording, and improved reviewer trust/acceptance of generated positioning.",
      "link": "https://www.onyx.app/92684"
    }
  ],
  "primary_owners": [
    "kevin_sullivan"
  ],
  "secondary_owners": []
}