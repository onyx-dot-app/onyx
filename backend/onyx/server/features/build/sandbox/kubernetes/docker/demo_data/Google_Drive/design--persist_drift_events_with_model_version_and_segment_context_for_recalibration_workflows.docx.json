{
  "id": "99130231c4ad4b1cbf6784f027178a80",
  "semantic_identifier": "Design--Persist drift events with model/version + segment context for recalibration workflows.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-10-26",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Persist drift events with model/version + segment context for recalibration workflows.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "We should introduce a durable `DriftEvent` entity that is created whenever GOLD-125 flags drift. The goal is to make drift detection actionable by capturing enough immutable context to reproduce and prioritize the issue later, rather than relying on ephemeral logs or recomputation. Each `DriftEvent` represents a single detection instance for a given model/version over a specific time window and provides a stable anchor for downstream recalibration workflows.\n\nThe `DriftEvent` record will include: `id`, `created_at`, `model_name`, `model_version`, `time_window_start/end`, `triggering_metrics` (e.g., metric name \u2192 observed value, baseline, threshold, direction), `detector_run_id` (link back to GOLD-125 execution), and `segments` (list of segment descriptors like `{key: \"industry\", value: \"SaaS\"}` plus any higher-level grouping such as ICP tier/region). To enable reproducibility, it will also store a lightweight \u201cdata snapshot pointer\u201d such as a `dataset_id` (preferred if we have a snapshotting mechanism) or a `query_fingerprint + params` bundle that can be executed deterministically (including the exact feature/label versions used, if applicable). This pointer is explicitly not the raw data; it\u2019s a stable reference that downstream jobs can use to fetch the same slice.\n\nOn drift detection, GOLD-125 will call a small persistence service (or write directly through the data access layer) to upsert a new `DriftEvent`. We should de-duplicate by a composite key like `(model_name, model_version, time_window_start, time_window_end, segment_hash, metric_set_hash)` to avoid noisy repeats from reruns, while still allowing multiple events when different segments/metrics fire. The event transitions are simple: `OPEN` on creation, optionally `ACKED`/`IN_PROGRESS` when triaged, and `RESOLVED` when a recalibration or model update is shipped (status changes can be manual initially).\n\nFinally, expose an internal API to support triage and prioritization: `GET /internal/drift-events` (filter by model/version, time window, segment keys/values, status, severity), `GET /internal/drift-events/{id}` (full details including snapshot pointer), and `PATCH /internal/drift-events/{id}` (status/owner/notes). This enables Sales Ops/Engineering to pull a queue of drift issues, inspect the exact affected segment and thresholds, and kick off evaluation/retraining jobs that consume the stored snapshot pointer to reproduce the slice without re-deriving it.",
      "link": "https://www.onyx.app/39872"
    }
  ],
  "primary_owners": [
    "brooke_spencer"
  ],
  "secondary_owners": []
}