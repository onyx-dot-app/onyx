{
  "id": "1da8b1dcb44c45fb916328d41465763e",
  "semantic_identifier": "Design--Add end-to-end regression tests for fit_estimation CSV import \u2192 scoring to catch type/mapping and validation issues.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-05-03",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Add end-to-end regression tests for fit_estimation CSV import \u2192 scoring to catch type/mapping and validation issues.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "We will add an end-to-end regression test suite that exercises the full `fit_estimation` pipeline from CSV import through normalization, scoring request construction, and the final scoring response (fit score plus driver breakdown). The goal is to catch regressions where CSV types or mappings drift (e.g., enums parsed incorrectly, numbers coerced unexpectedly) and to ensure validation failures are surfaced as structured errors instead of silently degrading scores. This suite will explicitly protect against the behaviors fixed in GOLD-1 (type/mapping issues) and the stricter input validation changes introduced in GOLD-2.\n\nThe tests will run against representative CSV fixtures checked into the repo, organized by scenario: \u201chappy path,\u201d \u201cenum variants,\u201d \u201cblanks/empty strings,\u201d \u201cNaN-like values,\u201d and \u201cout-of-range/invalid.\u201d For each fixture, we\u2019ll assert both (1) the normalized intermediate representation (or equivalent request payload) and (2) the exact payload sent to the scoring service, so the test fails if the normalization layer changes field names, types, defaulting behavior, or enum mapping. We\u2019ll keep fixtures small and readable while covering the fields historically implicated in scoring drift, and we\u2019ll pin expected outputs to deterministic snapshots/JSON assertions to make regressions obvious.\n\nFor invalid inputs, the suite will verify that the pipeline returns structured per-field errors (e.g., `{ rowIndex, field, code, message }`) and that invalid fields do not leak into the scoring request. We\u2019ll include cases where only some fields are invalid to confirm partial-row handling is correct (either row-level rejection or field-level nulling, depending on current product behavior), and we\u2019ll ensure the response clearly indicates which rows/fields failed validation. Where applicable, we\u2019ll assert that scores are not produced for invalid rows (or are produced only when validation passes), preventing \u201csilent scoring\u201d on corrupted data.\n\nImplementation-wise, we\u2019ll build these as black-box integration tests that invoke the same API/entrypoint used in production for CSV import and scoring, with the scoring service stubbed or run in a controlled test mode to capture the received payload and return deterministic responses. The test harness will record the normalized payload and the outbound scoring request (e.g., via a request spy, contract stub, or in-process adapter hook), then compare against expected JSON. The suite will run in CI, be fast enough to run on every PR, and will be the regression gate for future changes to CSV parsing, normalization, mapping tables, and validation rules in the `fit_estimation` pipeline.",
      "link": "https://www.onyx.app/15986"
    }
  ],
  "primary_owners": [
    "jason_morris"
  ],
  "secondary_owners": []
}