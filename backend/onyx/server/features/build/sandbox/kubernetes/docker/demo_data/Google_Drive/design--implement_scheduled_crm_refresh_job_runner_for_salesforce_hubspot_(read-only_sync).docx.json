{
  "id": "66feb7deeae54aec9bceb9b5d4e333ec",
  "semantic_identifier": "Design--Implement scheduled CRM refresh job runner for Salesforce/HubSpot (read-only sync).docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-08-03",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Implement scheduled CRM refresh job runner for Salesforce/HubSpot (read-only sync).docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "We will implement a backend scheduled job runner that periodically refreshes CRM data from Salesforce and HubSpot in a read-only manner, following the per-workspace refresh cadence configured in GOLD-79. The runner will be deployed as a recurring task (e.g., cron/queue scheduler) that enqueues a \u201cCRMRefreshRun\u201d per eligible workspace+connector, with concurrency controls to prevent overlapping runs for the same workspace/connector and to ensure predictable load on external APIs.\n\nEach run will ingest only the in-scope CRM objects and fields (as defined by existing connector configuration) and upsert into our internal sync tables. Incremental sync will be driven by a stored cursor per workspace/connector/object (e.g., last-sync timestamp and, where required by the API, a paging token) persisted in a dedicated state table. The runner will fetch changes since the last cursor, process pages deterministically, and update the cursor only after successful persistence to avoid data loss; idempotency will be handled via stable external IDs and upsert semantics in the sync tables.\n\nReliability will be provided via basic retries and backoff at the job and request level, with clear handling for transient errors (timeouts, 429s, 5xx) versus terminal failures (auth revoked, misconfiguration). We will record per-run logs and metrics including start/end time, objects attempted, records fetched/upserted, API calls, rate-limit events, retries, and final status; failures will capture an error classification and message for operator/debug visibility. Runs should be resumable: if a run fails mid-way, the next run continues from the last committed cursor.\n\nNon-goals for this ticket are deduplication across objects/sources and any write-back behavior to CRMs; this work strictly produces reliable periodic ingestion into internal sync tables. We will also avoid schema/field inference changes beyond reading the configured field list, and we will not implement downstream transformation/business logic here\u2014only the scheduled execution, incremental fetch, persistence, and observability needed for ongoing refresh.",
      "link": "https://www.onyx.app/78271"
    }
  ],
  "primary_owners": [
    "ryan_murphy"
  ],
  "secondary_owners": []
}