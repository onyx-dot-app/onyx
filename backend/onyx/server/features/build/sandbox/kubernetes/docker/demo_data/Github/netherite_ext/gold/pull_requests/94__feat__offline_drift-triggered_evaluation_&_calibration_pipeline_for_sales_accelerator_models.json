{
  "id": "https://github.com/onyx-dot-app/onyx#94",
  "semantic_identifier": "94: feat: Offline drift-triggered evaluation & calibration pipeline for Sales_Accelerator models",
  "title": null,
  "source": "github",
  "doc_updated_at": "2025-11-03",
  "metadata": {
    "object_type": "PullRequest",
    "id": "94",
    "merged": "False",
    "state": "open",
    "user": {
      "login": "michael_anderson",
      "name": "michael_anderson",
      "email": "michael_anderson@netherite-extraction.onyx.app"
    },
    "assignees": [
      {
        "login": "andre_robinson",
        "name": "andre_robinson",
        "email": "andre_robinson@netherite-extraction.onyx.app"
      }
    ],
    "repo": "netherite-ext/gold",
    "num_commits": "1",
    "num_files_changed": "91",
    "labels": [],
    "created_at": "2025-11-03",
    "updated_at": "2025-11-03",
    "closed_at": ""
  },
  "doc_metadata": {
    "repo": "netherite-ext/gold",
    "hierarchy": {
      "source_path": [
        "netherite-ext",
        "gold",
        "pull_requests"
      ],
      "owner": "netherite-ext",
      "repo": "gold",
      "object_type": "pull_request"
    }
  },
  "sections": [
    {
      "text": "## Description\r\n\r\nImplements an offline evaluation job that runs automatically when drift is flagged for Sales_Accelerator models.\n\nKey changes:\n- Adds a scheduled/triggerable job that listens for drift events from the existing drift-signal source and kicks off an evaluation run.\n- Snapshots a configurable \u201crecent window\u201d of data at trigger time and materializes segment-level slices (e.g., region/industry/customer tier) for consistent, reproducible scoring.\n- Runs a standardized evaluation suite across supported model types:\n  - Forecasting: regression/forecast error metrics (e.g., MAE/RMSE/MAPE where applicable) + segment breakdowns.\n  - Best-next-action: ranking/classification metrics (e.g., AUC/PR, top-k uplift/precision) + segment breakdowns.\n  - Risk alerts: alert quality metrics (e.g., precision/recall, FPR/FNR) + segment breakdowns.\n- Computes calibration outputs for probabilistic models:\n  - Brier score and reliability curve bins (per segment and overall).\n  - Stores bin counts, predicted probability averages, and observed rates to enable later plotting without recomputation.\n- Computes business KPI deltas vs the currently deployed model (champion vs current production version), producing a \u201cdegradation confirmation\u201d view rather than relying solely on drift signals.\n- Persists results in a new evaluation results store/table with metadata:\n  - model_name, model_version (candidate/champion), drift_event_id, snapshot_timeframe (start/end), segment keys, metrics payload, and job run id.\n- Includes config defaults (time window, segments, metric set per model family) and idempotency/partitioning so reruns for the same drift event do not duplicate records.\n\nOperational notes:\n- This is offline-only and does not change online inference paths.\n- The job can be run manually with a drift_event_id for backfills/debugging.\n- Output is intended to be the baseline artifact used by follow-up retraining/recalibration tickets.\r\n\r\n## How Has This Been Tested?\r\n\r\nstaging\r\n",
      "link": "https://github.com/onyx-dot-app/onyx#94"
    }
  ],
  "primary_owners": [],
  "secondary_owners": []
}