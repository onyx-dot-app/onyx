{
  "id": "d18fcdee4dea4745b0c46b846bc20c16",
  "semantic_identifier": "Design--Add observability for scheduled sync jobs across CRM, Support, and Product Analytics integrations.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-07-14",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Add observability for scheduled sync jobs across CRM, Support, and Product Analytics integrations.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "We will add consistent observability for all scheduled sync jobs across CRM, Support, and Product Analytics integrations by standardizing structured logs and emitting a shared set of metrics for every sync run. Each scheduled execution will generate a unique `sync_run_id` and log lifecycle events (start, progress checkpoints, end) with a common schema that includes integration type, connection ID, job/schedule ID, and run outcome. Metrics will capture start/end timestamps, duration, records read/processed/written (and optionally \u201cskipped/unchanged\u201d where relevant), external API error counts by class/status, retry counts, and final status (success/failed/canceled). This provides consistent, queryable signals across integrations without requiring deep knowledge of each connector\u2019s internal implementation.\n\nOn the connection model, we will persist a \u201csync status\u201d summary that can be surfaced in the product: `last_run_at`, `last_success_at`, `last_failure_at`, `last_failure_reason` (short code + human-readable message), and `last_run_status`. These fields will be updated atomically at the end of each run (and on terminal failure), using the `sync_run_id` to correlate UI status with logs/metrics. The goal is to make staleness explicit (\u201clast successful sync 3d ago\u201d) and actionable (\u201cfailing due to 401 invalid credentials\u201d vs \u201crate limited, retrying\u201d), and to decouple diagnosis from ad-hoc log spelunking.\n\nImplementation-wise, we will introduce a small shared \u201csync observability\u201d utility used by all scheduled sync entrypoints, providing a standard run wrapper (start timer, emit metrics, catch/normalize errors, record retries) and a canonical error taxonomy (auth, rate_limit, validation, upstream_5xx, network, unknown). Integrations can add connector-specific tags (e.g., object type) but must emit the required base fields to keep dashboards and alerts consistent. Where jobs already have partial logging, we will migrate to the shared wrapper to avoid duplicated conventions and ensure all runs produce comparable signals.\n\nFinally, we will create basic dashboards and alerts keyed by integration type and connection ID: failure rate over time, p95 duration, records processed, and top failure reasons, plus an alert for \u201cno successful run in N hours\u201d per connection (stale data). This feature is explicitly scoped to observability and status surfacing\u2014no functional changes to sync logic\u2014so subsequent tickets can iterate on reliability and correctness with a clear baseline for measuring impact and diagnosing issues.",
      "link": "https://www.onyx.app/36584"
    }
  ],
  "primary_owners": [
    "brooke_spencer"
  ],
  "secondary_owners": []
}