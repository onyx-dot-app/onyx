{
  "id": "2023a9f0f529456287bf15e0f3b7a1f4",
  "semantic_identifier": "Design--Implement fit score drift monitoring and alerting.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-12-03",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Implement fit score drift monitoring and alerting.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "We will implement automated drift monitoring for \u201cfit score\u201d model outputs to detect when the production score behavior deviates materially from a known-good baseline. The system will compute and persist daily (and optionally hourly) metrics per model version and key segments (e.g., customer tier, geography, acquisition channel), including score distribution summaries (mean/std, quantiles, PSI/KS, % above key thresholds) and, where labeled outcomes exist, lightweight performance signals (calibration error, AUC/log loss, and segment lift at top-K). Metrics will be computed from the same logged inference events used for analytics, joined to labels on a configurable delay window when available.\n\nA baseline will be defined per model version at launch (e.g., trailing 7\u201314 days after deploy, or an explicitly pinned reference window), and drift thresholds will be configurable per metric and segment. We will flag drift when metrics exceed absolute thresholds (e.g., PSI > X, calibration error delta > Y) or statistically significant shifts occur (e.g., KS test p-value below Z with minimum sample size), with guardrails for low-volume segments (minimum N, smoothing, and \u201cinsufficient data\u201d states). Each drift signal will be aggregated into a \u201cdrift event\u201d object capturing model version, metric, segment, baseline window, detected window, severity, and supporting charts/values.\n\nAlerting will be routed to Slack and email via an existing notification service, with deduplication and escalation rules (e.g., warn on first occurrence, critical if sustained for N intervals or if labeled performance drops beyond threshold). Alerts will include deep links to a \u201cDrift Report\u201d page (or dashboard) pre-filtered to model version/segment/time window, plus the exact metric deltas and sample sizes. To avoid noise, we\u2019ll implement cooldown periods, grouping of related metrics into a single alert, and suppression during known maintenance/replay periods.\n\nAll drift events and the underlying aggregated metrics will be stored in a dedicated table (e.g., `fit_score_drift_metrics`, `fit_score_drift_events`) to support audit, trend analysis, and retraining decisions. The design supports backfills for historical analysis and \u201creplay\u201d of new thresholds without recomputing raw logs by re-evaluating stored aggregates. Operational ownership will include a runbook describing how to interpret alerts, verify data integrity, and trigger follow-up actions (e.g., label pipeline checks, model rollback, or retraining ticket creation).",
      "link": "https://www.onyx.app/35525"
    }
  ],
  "primary_owners": [
    "jiwon_kang"
  ],
  "secondary_owners": []
}