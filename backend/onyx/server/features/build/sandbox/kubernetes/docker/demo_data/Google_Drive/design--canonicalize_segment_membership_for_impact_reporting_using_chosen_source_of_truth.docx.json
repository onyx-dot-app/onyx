{
  "id": "5bd11ebacaa7405fbb0baa9667bbb3f6",
  "semantic_identifier": "Design--Canonicalize segment membership for impact reporting using chosen source of truth.docx",
  "title": null,
  "source": "google_doc",
  "doc_updated_at": "2025-08-13",
  "metadata": {
    "owner_names": ""
  },
  "doc_metadata": {
    "hierarchy": {
      "source_path": [
        "My Drive"
      ],
      "drive_id": null,
      "file_name": "Design--Canonicalize segment membership for impact reporting using chosen source of truth.docx",
      "mime_type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    }
  },
  "sections": [
    {
      "text": "We will add a segment canonicalization layer to Issue_Tracker\u2019s impact-reporting pipeline so that all segment membership used in aggregation is computed from a single chosen \u201csource of truth\u201d (per GOLD-179), rather than mixing definitions across CRM and Customer_Analyzer. This layer will normalize segment identifiers and names into a canonical `SegmentKey` (e.g., stable ID + normalized display name) and produce a deterministic mapping from any incoming segment reference (IDs, names, aliases) to that key. The canonicalization step will run before any impacted-customer or impacted-revenue aggregation so downstream logic operates only on canonical segments.\n\nAt runtime, the pipeline will resolve the configured source of truth for each segment (or globally, depending on GOLD-179\u2019s decision) and compute membership exclusively from that system. Concretely: (1) ingest incident/issue impact inputs that reference segments; (2) canonicalize those segment references via a mapping table/service; (3) fetch membership lists (customer IDs/accounts) from the selected system; (4) join membership to revenue metrics and aggregate. We will expose the resolved source and canonical segment metadata in the impact report output to make attribution auditable.\n\nTo avoid silent corruption when a segment cannot be mapped or the two systems disagree, unmapped or ambiguous segment references will not be coerced into best-effort matches. Instead, the canonicalization layer will emit an explicit `UNKNOWN/MISMATCHED` segment classification with diagnostic context (original reference, attempted matches, source-of-truth expected, timestamp/version). Impact reporting will surface these as a separate bucket and/or warning state, and aggregation will exclude them from \u201ccanonical\u201d totals unless explicitly requested, ensuring we do not mix incompatible segment definitions.\n\nImplementation-wise, we will introduce a small canonicalization module (library or service) with a versioned mapping store (e.g., table keyed by external system + external ID/name -> canonical segment key, plus aliases), and a configuration flag indicating source-of-truth selection. We will add metrics/logging for mapping hit rate, unknown/mismatched counts, and source-of-truth fetch failures; and add tests that validate stable canonical keys, correct membership selection, and proper handling of unmapped segments. Rollout will be gated behind a feature flag with dual-run comparison (old vs canonicalized) to quantify deltas before fully switching impact reporting to canonical segments.",
      "link": "https://www.onyx.app/36076"
    }
  ],
  "primary_owners": [
    "kevin_sullivan"
  ],
  "secondary_owners": []
}