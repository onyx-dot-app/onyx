#!/usr/bin/env python3
"""
ocli - Dependency Management CLI using uv
Manages Python dependencies across multiple requirement sets with automatic freezing.
"""

import argparse
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import Dict
from typing import List

# Configuration
REPO_ROOT = Path(__file__).resolve().parent
REQ_DIR = REPO_ROOT / "backend" / "requirements" / "in"
FROZEN_DIR = REPO_ROOT / "backend" / "requirements" / "frozen"

REQUIREMENT_SETS = {
    "default": str(REQ_DIR / "default.in"),
    "ee": str(REQ_DIR / "ee.in"),
    "dev": str(REQ_DIR / "dev.in"),
    "model_server": str(REQ_DIR / "model_server.in"),
    "local_dev": str(REQ_DIR / "local_dev.in"),
}

COMPILED_FILES = {
    "default": str(FROZEN_DIR / "default.txt"),
    "ee": str(FROZEN_DIR / "ee.txt"),
    "dev": str(FROZEN_DIR / "dev.txt"),
    "model_server": str(FROZEN_DIR / "model_server.txt"),
    "local_dev": str(FROZEN_DIR / "local_dev.txt"),
}

# Valid installation combinations
VALID_COMBINATIONS = [
    ["default", "dev", "model_server"],
    ["default", "dev"],
    ["default", "ee"],
    ["model_server"],
    ["default", "ee", "dev"],
    ["default", "ee", "dev", "model_server", "local_dev"],
]


def run_command(cmd: List[str], check=True) -> subprocess.CompletedProcess:
    """Run a command and return the result."""
    print(f"Running: {' '.join(cmd)}")
    return subprocess.run(cmd, check=check, capture_output=False)


def ensure_uv_installed():
    """Check if uv is installed."""
    try:
        subprocess.run(["uv", "--version"], check=True, capture_output=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("Error: uv is not installed. Install it with: pip install uv")
        sys.exit(1)


def initialize_project():
    """Initialize virtual environment in project root."""
    ensure_uv_installed()

    print(f"Initializing virtual environment in {REPO_ROOT}")
    cmd = ["uv", "venv"]
    run_command(cmd)
    print("\n✓ Virtual environment created successfully!")
    print("Activate it with: source .venv/bin/activate")


def add_dependency(package: str, target_sets: List[str]):
    """Add a dependency to specified requirement sets."""
    ensure_uv_installed()

    for target in target_sets:
        if target not in REQUIREMENT_SETS:
            print(f"Error: Unknown requirement set '{target}'")
            print(f"Valid sets: {', '.join(REQUIREMENT_SETS.keys())}")
            sys.exit(1)

    # Add package to each .in file
    for target in target_sets:
        in_file = Path(REQUIREMENT_SETS[target])

        # Read existing content
        if in_file.exists():
            content = in_file.read_text()
            lines = content.splitlines()
        else:
            lines = []

        # Check if package already exists
        package_name = (
            package.split("[")[0].split("==")[0].split(">=")[0].split("<=")[0]
        )

        # Find existing package line index
        existing_index = None
        for i, line in enumerate(lines):
            if line.strip().startswith(package_name) and not line.strip().startswith(
                "#"
            ):
                existing_index = i
                break

        if existing_index is not None:
            # Replace existing package
            lines[existing_index] = package
            in_file.write_text("\n".join(lines) + "\n")
            print(f"Replaced '{package_name}' with '{package}' in {in_file}")
        else:
            # Add new package
            lines.append(package)
            in_file.write_text("\n".join(lines) + "\n")
            print(f"Added '{package}' to {in_file}")

    # Recompile all valid combinations
    print("\nRecompiling all valid combinations...")
    compile_all_combinations()
    sync_environment()


def remove_dependency(package: str, target_sets: List[str]):
    """Remove a dependency from specified requirement sets."""
    ensure_uv_installed()

    for target in target_sets:
        if target not in REQUIREMENT_SETS:
            print(f"Error: Unknown requirement set '{target}'")
            sys.exit(1)

    package_name = package.split("[")[0].split("==")[0].split(">=")[0].split("<=")[0]

    for target in target_sets:
        in_file = Path(REQUIREMENT_SETS[target])

        if not in_file.exists():
            continue

        lines = in_file.read_text().splitlines()
        new_lines = [
            line
            for line in lines
            if not (
                line.strip().startswith(package_name)
                and not line.strip().startswith("#")
            )
        ]

        if len(new_lines) != len(lines):
            in_file.write_text("\n".join(new_lines) + "\n")
            print(f"Removed '{package_name}' from {in_file}")
        else:
            print(f"Package '{package_name}' not found in {in_file}")

    print("\nRecompiling all valid combinations...")
    compile_all_combinations()
    sync_environment()


def compile_combination(combination: List[str]) -> str:
    """
    Compile a specific combination of requirement sets together.
    Returns the compiled content as a string.
    """
    ensure_uv_installed()

    # Create a temporary combined input file
    with tempfile.NamedTemporaryFile(mode="w", suffix=".in", delete=False) as tmp:
        tmp_path = Path(tmp.name)

        # Write all input files to the temp file with markers
        for name in combination:
            in_file = REQUIREMENT_SETS[name]
            if not Path(in_file).exists():
                print(f"Warning: {in_file} does not exist, skipping")
                continue

            tmp.write(f"# --- {name} ---\n")
            content = Path(in_file).read_text()
            # Filter out comments and empty lines for cleaner compilation
            lines = [
                line
                for line in content.splitlines()
                if line.strip() and not line.strip().startswith("#")
            ]
            tmp.write("\n".join(lines) + "\n")

    try:
        # Compile the combined file
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".txt", delete=False
        ) as out_tmp:
            out_tmp_path = Path(out_tmp.name)

        cmd = [
            "uv",
            "pip",
            "compile",
            str(tmp_path),
            "--output-file",
            str(out_tmp_path),
            "--generate-hashes",
        ]

        print(f"\nCompiling combination: {', '.join(combination)}")
        run_command(cmd)

        # Read the compiled output
        compiled_content = out_tmp_path.read_text()

        return compiled_content

    finally:
        # Cleanup temp files
        tmp_path.unlink(missing_ok=True)
        if "out_tmp_path" in locals():
            out_tmp_path.unlink(missing_ok=True)


def extract_package_versions(compiled_content: str) -> Dict[str, str]:
    """Extract package name -> full spec mapping from compiled requirements."""
    packages = {}
    lines = compiled_content.splitlines()

    i = 0
    while i < len(lines):
        line = lines[i].strip()

        # Skip comments and empty lines
        if not line or line.startswith("#"):
            i += 1
            continue

        # Parse package line (may span multiple lines with hashes)
        full_spec = line
        i += 1

        # Collect continuation lines (hashes)
        while i < len(lines) and lines[i].strip().startswith("--hash="):
            full_spec += "\n" + lines[i]
            i += 1

        # Extract package name
        package_name = line.split("==")[0].split("[")[0].strip().lower()
        packages[package_name] = full_spec

    return packages


def compile_all_combinations():
    """
    Compile all valid combinations and extract individual .txt files.
    Uses a universal resolution strategy: compile all sets together once,
    then filter down to individual files. This guarantees consistency.
    """
    ensure_uv_installed()

    print(f"\n{'='*60}")
    print("Step 1: Compiling universal resolution (all sets together)")
    print(f"{'='*60}")

    # Compile all sets together to get universal versions
    all_sets = list(REQUIREMENT_SETS.keys())
    universal_content = compile_combination(all_sets)
    universal_packages = extract_package_versions(universal_content)

    print(f"  ✓ Resolved {len(universal_packages)} total packages")

    print(f"\n{'='*60}")
    print("Step 2: Writing individual requirement files")
    print(f"{'='*60}")

    # For each requirement set, figure out which packages it needs
    # by compiling it individually (but we'll use versions from universal resolution)
    for set_name, out_file in COMPILED_FILES.items():
        in_file = REQUIREMENT_SETS[set_name]

        if not Path(in_file).exists():
            print(f"\nSkipping {out_file} (no {in_file})")
            continue

        print(f"\nProcessing {set_name}:")

        # Compile this set alone to find which packages it needs
        # (not for versions, just to know the dependency tree)
        individual_content = compile_combination([set_name])
        needed_packages = set(extract_package_versions(individual_content).keys())

        print(f"  - Needs {len(needed_packages)} packages")

        # Now write the output using versions from universal resolution
        missing_packages = []
        with open(out_file, "w") as f:
            f.write("# This file is autogenerated by ocli\n")
            f.write("# Do not edit manually - use 'ocli add' or 'ocli remove'\n")
            f.write("# Source: {in_file}\n")
            f.write("# Resolved with universal compilation for consistency\n\n")

            written = 0
            for pkg_name in sorted(needed_packages):
                if pkg_name in universal_packages:
                    f.write(universal_packages[pkg_name] + "\n")
                    written += 1
                else:
                    missing_packages.append(pkg_name)

            print(f"  ✓ Wrote {written} packages to {out_file}")

            if missing_packages:
                print(
                    f"  ⚠ Warning: {len(missing_packages)} packages not in universal resolution:"
                )
                for pkg in missing_packages[:5]:  # Show first 5
                    print(f"    - {pkg}")
                if len(missing_packages) > 5:
                    print(f"    ... and {len(missing_packages) - 5} more")

    print(f"\n{'='*60}")
    print("✓ All requirement files compiled successfully!")
    print(f"{'='*60}")

    # Verify all combinations still work
    print("\nVerifying all combinations resolve correctly...")
    verify_all_combinations()


def verify_all_combinations():
    """Verify that all valid combinations can be resolved together."""
    ensure_uv_installed()

    all_valid = True

    for combination in VALID_COMBINATIONS:
        txt_files = [COMPILED_FILES[name] for name in combination]

        # Check all files exist
        missing = [f for f in txt_files if not Path(f).exists()]
        if missing:
            print(f"  ✗ {', '.join(combination)}: Missing files {missing}")
            all_valid = False
            continue

        # Try to compile them together to check for conflicts
        with tempfile.NamedTemporaryFile(mode="w", suffix=".in", delete=False) as tmp:
            tmp_path = Path(tmp.name)
            for txt_file in txt_files:
                tmp.write(f"-r {txt_file}\n")

        try:
            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".txt", delete=False
            ) as out_tmp:
                out_tmp_path = Path(out_tmp.name)

            cmd = [
                "uv",
                "pip",
                "compile",
                str(tmp_path),
                "--output-file",
                str(out_tmp_path),
                "--quiet",
            ]

            result = subprocess.run(cmd, check=False, capture_output=True)

            if result.returncode == 0:
                print(f"  ✓ {', '.join(combination)}")
            else:
                print(f"  ✗ {', '.join(combination)}: Compilation failed")
                print(result.stderr.decode())
                all_valid = False

        finally:
            tmp_path.unlink(missing_ok=True)
            if "out_tmp_path" in locals():
                out_tmp_path.unlink(missing_ok=True)

    if all_valid:
        print("\n✓ All combinations verified successfully!")
    else:
        print("\n✗ Some combinations failed verification")
        sys.exit(1)


def sync_environment():
    """Install all dependencies using uv pip sync."""
    ensure_uv_installed()

    # Always sync all sets together
    all_sets = list(REQUIREMENT_SETS.keys())
    txt_files = [COMPILED_FILES[name] for name in all_sets]

    # Check all files exist
    missing = [txt_file for txt_file in txt_files if not Path(txt_file).exists()]
    if missing:
        print(f"Error: Missing compiled files: {', '.join(missing)}")
        print("Run './ocli compile' first.")
        sys.exit(1)

    # Use uv pip sync for clean installation
    cmd = ["uv", "pip", "sync"] + txt_files
    print(f"\nSyncing environment with all requirement sets: {', '.join(all_sets)}")
    print(f"Files: {', '.join(txt_files)}")
    run_command(cmd)
    print("\n✓ Environment synced successfully!")
    print("\nNote: For production/CI with specific combinations, use:")
    print("  uv pip sync backend/requirements/frozen/<files>.txt")


def list_dependencies():
    """List all dependencies in each requirement set."""
    for name, in_file in REQUIREMENT_SETS.items():
        filepath = Path(in_file)
        print(f"\n{name.upper()} ({in_file}):")
        if filepath.exists():
            content = filepath.read_text()
            deps = [
                line.strip()
                for line in content.splitlines()
                if line.strip() and not line.strip().startswith("#")
            ]
            if deps:
                for dep in deps:
                    print(f"  - {dep}")
            else:
                print("  (empty)")
        else:
            print("  (file does not exist)")


def main():
    parser = argparse.ArgumentParser(
        description="Manage Python dependencies across multiple requirement sets using uv"
    )
    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # init command
    subparsers.add_parser("init", help="Initialize requirement files")

    # add command
    add_parser = subparsers.add_parser("add", help="Add a dependency")
    add_parser.add_argument("package", help="Package to add (e.g., 'requests>=2.28.0')")
    add_parser.add_argument(
        "--to",
        nargs="+",
        required=True,
        choices=list(REQUIREMENT_SETS.keys()),
        help="Target requirement set(s)",
    )

    # remove command
    remove_parser = subparsers.add_parser("remove", help="Remove a dependency")
    remove_parser.add_argument("package", help="Package to remove")
    remove_parser.add_argument(
        "--from",
        dest="from_sets",
        nargs="+",
        required=True,
        choices=list(REQUIREMENT_SETS.keys()),
        help="Target requirement set(s)",
    )

    # compile command
    subparsers.add_parser("compile", help="Compile all valid combinations")

    # sync command
    subparsers.add_parser(
        "sync", help="Sync environment with ALL requirement sets (local dev)"
    )

    # list command
    subparsers.add_parser("list", help="List all dependencies")

    # verify command
    subparsers.add_parser("verify", help="Verify all combinations resolve correctly")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    if args.command == "init":
        initialize_project()
    elif args.command == "add":
        add_dependency(args.package, args.to)
    elif args.command == "remove":
        remove_dependency(args.package, args.from_sets)
    elif args.command == "compile":
        compile_all_combinations()
    elif args.command == "sync":
        sync_environment()
    elif args.command == "list":
        list_dependencies()
    elif args.command == "verify":
        verify_all_combinations()


if __name__ == "__main__":
    main()
