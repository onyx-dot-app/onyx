name: Nightly LLM Provider Chat Tests (OpenAI)
concurrency:
  group: Nightly-LLM-Provider-Chat-OpenAI-${{ github.workflow }}-${{ github.run_id }}
  cancel-in-progress: true

on:
  schedule:
    # Runs daily at 10:30 UTC (2:30 AM PST / 3:30 AM PDT)
    - cron: "30 10 * * *"
  workflow_dispatch:

permissions:
  contents: read

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  NIGHTLY_LLM_OPENAI_MODELS: ${{ vars.NIGHTLY_LLM_OPENAI_MODELS }}

jobs:
  build-backend-image:
    runs-on:
      [
        runs-on,
        runner=1cpu-linux-arm64,
        "run-id=${{ github.run_id }}-build-backend-image",
        "extras=ecr-cache",
      ]
    timeout-minutes: 45
    steps:
      - uses: runs-on/action@cd2b598b0515d39d78c38a02d529db87d2196d1e # ratchet:runs-on/action@v2

      - name: Checkout code
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # ratchet:actions/checkout@v6
        with:
          persist-credentials: false

      - name: Format branch name for cache
        id: format-branch
        env:
          PR_NUMBER: ${{ github.event.pull_request.number }}
          REF_NAME: ${{ github.ref_name }}
        run: |
          if [ -n "${PR_NUMBER}" ]; then
            CACHE_SUFFIX="${PR_NUMBER}"
          else
            # shellcheck disable=SC2001
            CACHE_SUFFIX=$(echo "${REF_NAME}" | sed 's/[^A-Za-z0-9._-]/-/g')
          fi
          echo "cache-suffix=${CACHE_SUFFIX}" >> $GITHUB_OUTPUT

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # ratchet:docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 # ratchet:docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: Build and push Backend Docker image
        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # ratchet:docker/build-push-action@v6
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ env.RUNS_ON_ECR_CACHE }}:nightly-llm-it-backend-${{ github.run_id }}
          cache-from: |
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:backend-cache-${{ github.sha }}
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:backend-cache-${{ steps.format-branch.outputs.cache-suffix }}
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:backend-cache
            type=registry,ref=onyxdotapp/onyx-backend:latest
          cache-to: |
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:backend-cache-${{ github.sha }},mode=max
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:backend-cache-${{ steps.format-branch.outputs.cache-suffix }},mode=max
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:backend-cache,mode=max
          no-cache: ${{ vars.DOCKER_NO_CACHE == 'true' }}

  build-model-server-image:
    runs-on:
      [
        runs-on,
        runner=1cpu-linux-arm64,
        "run-id=${{ github.run_id }}-build-model-server-image",
        "extras=ecr-cache",
      ]
    timeout-minutes: 45
    steps:
      - uses: runs-on/action@cd2b598b0515d39d78c38a02d529db87d2196d1e # ratchet:runs-on/action@v2

      - name: Checkout code
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # ratchet:actions/checkout@v6
        with:
          persist-credentials: false

      - name: Format branch name for cache
        id: format-branch
        env:
          PR_NUMBER: ${{ github.event.pull_request.number }}
          REF_NAME: ${{ github.ref_name }}
        run: |
          if [ -n "${PR_NUMBER}" ]; then
            CACHE_SUFFIX="${PR_NUMBER}"
          else
            # shellcheck disable=SC2001
            CACHE_SUFFIX=$(echo "${REF_NAME}" | sed 's/[^A-Za-z0-9._-]/-/g')
          fi
          echo "cache-suffix=${CACHE_SUFFIX}" >> $GITHUB_OUTPUT

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # ratchet:docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 # ratchet:docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: Build and push Model Server Docker image
        uses: docker/build-push-action@263435318d21b8e681c14492fe198d362a7d2c83 # ratchet:docker/build-push-action@v6
        with:
          context: ./backend
          file: ./backend/Dockerfile.model_server
          push: true
          tags: ${{ env.RUNS_ON_ECR_CACHE }}:nightly-llm-it-model-server-${{ github.run_id }}
          cache-from: |
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:model-server-cache-${{ github.sha }}
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:model-server-cache-${{ steps.format-branch.outputs.cache-suffix }}
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:model-server-cache
            type=registry,ref=onyxdotapp/onyx-model-server:latest
          cache-to: |
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:model-server-cache-${{ github.sha }},mode=max
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:model-server-cache-${{ steps.format-branch.outputs.cache-suffix }},mode=max
            type=registry,ref=${{ env.RUNS_ON_ECR_CACHE }}:model-server-cache,mode=max

  build-integration-image:
    runs-on:
      [
        runs-on,
        runner=2cpu-linux-arm64,
        "run-id=${{ github.run_id }}-build-integration-image",
        "extras=ecr-cache",
      ]
    timeout-minutes: 45
    steps:
      - uses: runs-on/action@cd2b598b0515d39d78c38a02d529db87d2196d1e # ratchet:runs-on/action@v2

      - name: Checkout code
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # ratchet:actions/checkout@v6
        with:
          persist-credentials: false

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@8d2750c68a42422c14e847fe6c8ac0403b4cbd6f # ratchet:docker/setup-buildx-action@v3

      - name: Login to Docker Hub
        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 # ratchet:docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: Format branch name for cache
        id: format-branch
        env:
          PR_NUMBER: ${{ github.event.pull_request.number }}
          REF_NAME: ${{ github.ref_name }}
        run: |
          if [ -n "${PR_NUMBER}" ]; then
            CACHE_SUFFIX="${PR_NUMBER}"
          else
            # shellcheck disable=SC2001
            CACHE_SUFFIX=$(echo "${REF_NAME}" | sed 's/[^A-Za-z0-9._-]/-/g')
          fi
          echo "cache-suffix=${CACHE_SUFFIX}" >> $GITHUB_OUTPUT

      - name: Build and push integration test image with Docker Bake
        env:
          INTEGRATION_REPOSITORY: ${{ env.RUNS_ON_ECR_CACHE }}
          TAG: nightly-llm-it-${{ github.run_id }}
          CACHE_SUFFIX: ${{ steps.format-branch.outputs.cache-suffix }}
          HEAD_SHA: ${{ github.sha }}
        run: |
          docker buildx bake --push \
            --set backend.cache-from=type=registry,ref=${RUNS_ON_ECR_CACHE}:backend-cache-${HEAD_SHA} \
            --set backend.cache-from=type=registry,ref=${RUNS_ON_ECR_CACHE}:backend-cache-${CACHE_SUFFIX} \
            --set backend.cache-from=type=registry,ref=${RUNS_ON_ECR_CACHE}:backend-cache \
            --set backend.cache-from=type=registry,ref=onyxdotapp/onyx-backend:latest \
            --set backend.cache-to=type=registry,ref=${RUNS_ON_ECR_CACHE}:backend-cache-${HEAD_SHA},mode=max \
            --set backend.cache-to=type=registry,ref=${RUNS_ON_ECR_CACHE}:backend-cache-${CACHE_SUFFIX},mode=max \
            --set backend.cache-to=type=registry,ref=${RUNS_ON_ECR_CACHE}:backend-cache,mode=max \
            --set integration.cache-from=type=registry,ref=${RUNS_ON_ECR_CACHE}:integration-cache-${HEAD_SHA} \
            --set integration.cache-from=type=registry,ref=${RUNS_ON_ECR_CACHE}:integration-cache-${CACHE_SUFFIX} \
            --set integration.cache-from=type=registry,ref=${RUNS_ON_ECR_CACHE}:integration-cache \
            --set integration.cache-to=type=registry,ref=${RUNS_ON_ECR_CACHE}:integration-cache-${HEAD_SHA},mode=max \
            --set integration.cache-to=type=registry,ref=${RUNS_ON_ECR_CACHE}:integration-cache-${CACHE_SUFFIX},mode=max \
            --set integration.cache-to=type=registry,ref=${RUNS_ON_ECR_CACHE}:integration-cache,mode=max \
            integration

  openai-provider-chat-test:
    needs:
      [build-backend-image, build-model-server-image, build-integration-image]
    runs-on:
      - runs-on
      - runner=4cpu-linux-arm64
      - "run-id=${{ github.run_id }}-nightly-openai-provider-chat-test"
      - extras=ecr-cache
    timeout-minutes: 45
    steps:
      - uses: runs-on/action@cd2b598b0515d39d78c38a02d529db87d2196d1e # ratchet:runs-on/action@v2

      - name: Checkout code
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # ratchet:actions/checkout@v6
        with:
          persist-credentials: false

      - name: Login to Docker Hub
        uses: docker/login-action@c94ce9fb468520275223c153574b00df6fe4bcc9 # ratchet:docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}

      - name: Create .env file for Docker Compose
        env:
          ECR_CACHE: ${{ env.RUNS_ON_ECR_CACHE }}
          RUN_ID: ${{ github.run_id }}
        run: |
          cat <<EOF > deployment/docker_compose/.env
          COMPOSE_PROFILES=s3-filestore
          ENABLE_PAID_ENTERPRISE_EDITION_FEATURES=true
          LICENSE_ENFORCEMENT_ENABLED=false
          AUTH_TYPE=basic
          POSTGRES_POOL_PRE_PING=true
          POSTGRES_USE_NULL_POOL=true
          REQUIRE_EMAIL_VERIFICATION=false
          DISABLE_TELEMETRY=true
          INTEGRATION_TESTS_MODE=true
          AUTO_LLM_UPDATE_INTERVAL_SECONDS=10
          ONYX_BACKEND_IMAGE=${ECR_CACHE}:nightly-llm-it-backend-${RUN_ID}
          ONYX_MODEL_SERVER_IMAGE=${ECR_CACHE}:nightly-llm-it-model-server-${RUN_ID}
          EOF

      - name: Start Docker containers
        run: |
          cd deployment/docker_compose
          docker compose -f docker-compose.yml -f docker-compose.dev.yml up \
            relational_db \
            index \
            cache \
            minio \
            api_server \
            inference_model_server \
            indexing_model_server \
            background \
            -d

      - name: Wait for API server health endpoint
        run: |
          start_time=$(date +%s)
          timeout=300
          while true; do
            current_time=$(date +%s)
            elapsed_time=$((current_time - start_time))
            if [ $elapsed_time -ge $timeout ]; then
              echo "Timeout reached waiting for API server health endpoint."
              exit 1
            fi

            response=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/health || echo "curl_error")
            if [ "$response" = "200" ]; then
              echo "API server is ready."
              break
            fi

            sleep 5
          done

      - name: Run OpenAI nightly provider integration test
        env:
          MODELS: ${{ env.NIGHTLY_LLM_OPENAI_MODELS }}
        run: |
          if [ -z "${MODELS}" ]; then
            MODELS="gpt-4o-mini"
          fi

          docker run --rm --network onyx_default \
            --name test-runner \
            -e POSTGRES_HOST=relational_db \
            -e POSTGRES_USER=postgres \
            -e POSTGRES_PASSWORD=password \
            -e POSTGRES_DB=postgres \
            -e DB_READONLY_USER=db_readonly_user \
            -e DB_READONLY_PASSWORD=password \
            -e POSTGRES_POOL_PRE_PING=true \
            -e POSTGRES_USE_NULL_POOL=true \
            -e VESPA_HOST=index \
            -e REDIS_HOST=cache \
            -e API_SERVER_HOST=api_server \
            -e TEST_WEB_HOSTNAME=test-runner \
            -e NIGHTLY_LLM_PROVIDER="openai" \
            -e NIGHTLY_LLM_MODELS="${MODELS}" \
            -e NIGHTLY_LLM_API_KEY="${OPENAI_API_KEY}" \
            -e NIGHTLY_LLM_STRICT="true" \
            ${{ env.RUNS_ON_ECR_CACHE }}:nightly-llm-it-${{ github.run_id }} \
            /app/tests/integration/tests/llm_workflows/test_nightly_provider_chat_workflow.py

      - name: Dump API server logs
        if: always()
        run: |
          cd deployment/docker_compose
          docker compose logs --no-color api_server > $GITHUB_WORKSPACE/api_server.log || true

      - name: Dump all-container logs
        if: always()
        run: |
          cd deployment/docker_compose
          docker compose logs --no-color > $GITHUB_WORKSPACE/docker-compose.log || true

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f
        with:
          name: docker-all-logs-nightly-openai-llm-provider
          path: ${{ github.workspace }}/docker-compose.log

      - name: Stop Docker containers
        if: always()
        run: |
          cd deployment/docker_compose
          docker compose down -v

  notify-slack-on-failure:
    needs: [openai-provider-chat-test]
    if: failure() && github.event_name == 'schedule'
    runs-on: ubuntu-slim
    timeout-minutes: 5
    steps:
      - name: Send Slack notification
        uses: ./.github/actions/slack-notify
        with:
          webhook-url: ${{ secrets.SLACK_WEBHOOK }}
          failed-jobs: openai-provider-chat-test
          title: "ðŸš¨ Scheduled OpenAI Provider Chat Tests failed!"
          ref-name: ${{ github.ref_name }}
